<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<title>MEGA DatA Lab</title>
<style type="text/css">
.class1 {
	color: #093;
}
.class2 {
	color: #00F;
}
.class2 font {
	color: #009;
}
</style>

<!-- style type="text/css">

/* All Styles Optional */

* {
font-family:calibri,arial;
font-size:16pt;
}

div#show {
background-color:#efefe7;
width:400px;
margin:0; padding:2px;
border:1px solid #909090;
}

div#show table input,  div#show4 table input {
outline-style:none;
}

</style -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript"
  src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script src="swissarmy.js" type="text/javascript"></script>

<script src="slideshow.js" type="text/javascript"></script>

</head>

<body style="background-color:#e6e6e6">
<h1 align="center"><font color="#000080">MEGA DatA Lab</font></h1>
<h2 align="center"><span class="class1"><span class="class"> Model Estimation, Graphical Algorithms, Data Analysis Lab</span></span></h2>
<p align="center">EECS, University of California, Irvine, CA 92697.</p>
<hr />

<h3><strong><font color="#990099">Mixtures of Graphical Models</font></strong></h3>
<p>We consider unsupervised estimation of mixtures of discrete graphical models, where the class variable corresponding to the mixture components is hidden and each mixture component over the observed variables can have a potentially different Markov graph structure and parameters. We propose a novel moment-based approach for estimating the mixture components, and our output is a tree-mixture model which serves as a good approximation to the underlying graphical model mixture. Our method is efficient when the union graph, which is the union of the Markov graphs of the mixture components with sparse vertex separators between any pair of observed variables. This includes tree mixtures and mixtures of bounded degree graphs. For such models, we prove that our method correctly recovers the union graph structure and the tree structures corresponding to maximumlikelihood tree approximations of the mixture components. The sample and computational complexities of our method scale as poly$(p, r)$, for an $r$-component mixture of $p$-variate graphical models. Our approach offers a powerful alternative to heuristics such as expectation maximization (EM) for learning mixture models.</p>
<p><strong>&ldquo;Learning High-Dimensional Mixtures of Graphical Models &rdquo;</strong>&nbsp;by A. Anandkumar, D. Hsu, F. Huang, and S.M. Kakade.&nbsp;<em>An abridged version appears in NIPS 2012.&nbsp;</em><br />
Download:&nbsp;<a href="http://newport.eecs.uci.edu/anandkumar/pubs/AnandkumarEtal_graphicalmixtures12.pdf">PDF.</a>&nbsp;<a href="http://newport.eecs.uci.edu/anandkumar/pubs/AnandkumarLIDS12.pdf">Slides.</a>&nbsp;<a href="http://newport.eecs.uci.edu/anandkumar/pubs/AnandkumarHsuHuangKakadeNIPS12.pdf">NIPS-version</a></p>
<p align="left">&nbsp;</p>

<hr />

<p align="left"></p>
<p align="left">&nbsp;</p>

</body>
</html>
