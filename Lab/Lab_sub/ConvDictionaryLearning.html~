<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Convolutional Dictionary Learning through Tensor Factorization</title>
<style type="text/css">
.class1 {	color: #093;
}
.class2 {	color: #00F;
}
</style>
</head>

<body style="background-color:#e6e6e6">
<h1 align="center"><font color="#000080">MEGA DatA Lab</font></h1>
<h2 align="center"><span class="class1"><span class="class"> Model Estimation, Graphical Algorithms, Data Analysis Lab</span></span></h2>
<p align="center">EECS, University of California, Irvine, CA 92697.</p>
<hr />
<h3 align="left"><font color="#990099">Convolutional Dictionary Learning through Tensor Factorization</font></h3>
<p>Tensor methods have emerged as a powerful paradigm for consistent learning of many latent variable models such as topic models, independent component analysis and dictionary learning. Model parameters are estimated via CP decomposition of the observed higher order input moments. However, in many domains, additional invariances such as shift invariances exist, enforced via models such as convolutional dictionary learning. In this paper, we develop novel tensor decomposition algorithms for parameter estimation of convolutional models. Our algorithm is based on the popular alternating least squares method, but with efficient projections onto the space of stacked circulant matrices. Our method is embarrassingly parallel and consists of simple operations such as fast Fourier transforms and matrix multiplications. Our algorithm converges to the dictionary much faster and more accurately compared to the alternating minimization over filters and activation maps.</p>



<p align="left">&nbsp;</p>
<p align="left"><strong><b>[1] </b>Convolutional Dictionary Learning through Tensor Factorization</strong><b>. </b>by  Furong Huang, Anima Anandkumar. <em>Preprint arXiv:1506.03509 [cs.LG]</em><br />
Download: <a href="../../pubs/0arxiv_tensorconv.pdf">PDF</a>. <a href="https://github.com/FurongHuang/ConvDicLearnTensorFactor">Code</a>.<em></em></p>





<p align="left"><img src="../../pubs/1dconv-2filters.png" width="1000" height="300" alt="Convolution Model" /></p>
<blockquote>
  <blockquote>&nbsp;</blockquote>
</blockquote>



<p align="left"><img src="../../pubs/tensor-decomp-conv.png" width="1000" height="300" alt="Two Subtrees" /></p>
<blockquote>
  <blockquote>&nbsp;</blockquote>
</blockquote>



<p align="left"><img src="../../pubs/filter12reconstruct_err.png" width="1000" height="300" alt="Two Subtrees" /></p>
<blockquote>
  <blockquote>&nbsp;</blockquote>
</blockquote>


<p align="left"><img src="../../pubs/runTime.png" width="1000" height="300" alt="Two Subtrees" /></p>
<blockquote>
  <blockquote>&nbsp;</blockquote>
</blockquote>
</body>
</html>
